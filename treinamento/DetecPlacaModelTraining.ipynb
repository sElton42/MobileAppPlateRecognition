{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"LteZiT4P5iGW"},"outputs":[],"source":["import torch # Importa biblioteca do pytorch\n","!python --version\n","from IPython.display import Image # Importa biblioteca para printar imagens"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5exHMQuYCKy-"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive') # importa arquivos do google drive para o disco da máquina virtual"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kqKEmeQykKN3"},"outputs":[],"source":["!mkdir imagens\n","!unzip [CAMINHO DATASET UFPR] -d /content/imagens/ # descompacta imagens a serem utilizadas no treinamento/teste/validação\n","!git clone https://github.com/ultralytics/yolov5 # importa yolov5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1-K6HoWl5iGg"},"outputs":[],"source":["%cd yolov5\n","!pip install -r requirements.txt # instala bibliotecas necessárias para utilizar o yolov5\n","!pip install IProgress"]},{"cell_type":"markdown","metadata":{"id":"72WTm2Cr5iGp"},"source":["# Treinamento do Modelo YoloV5"]},{"cell_type":"markdown","metadata":{"id":"aNSlUEGz5iGt"},"source":[" > Copiar arquivos para treinamento.\n","\n"," > Copiar arquivo dataset.yaml para o Diretório: yolov5/data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5wJHN0yd5iGv"},"outputs":[],"source":["!python train.py --img 1056 --batch 8 --epochs 10 --data dataset.yaml --weights yolov5n.pt --cache"]},{"cell_type":"markdown","metadata":{"id":"nU8Sbqz-NKl2"},"source":["> Copia resultados do treinamento para pasta no google drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GQJ6ujBv0y3S"},"outputs":[],"source":["!cp -r /content/yolov5/runs/train/exp2/ -d [CAMINHO PARA SALVAR RESULTADOS]"]},{"cell_type":"markdown","metadata":{"id":"qXPJ8diL5iGx"},"source":["# Testando o Modelo Treinado:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rZrtGIlG5iG2"},"outputs":[],"source":["!python detect.py --weights [MODELO TREINADO] --img 1056 --conf 0.25 --source [CAMINHO ARQUIVOS DE TESTES]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FXHBpWJ-2kzK"},"outputs":[],"source":["# COPIA RESULTADOS\n","!cp -r /content/yolov5/runs/detect/exp/ -d [CAMINHO PARA SALVAR RESULTADOS]"]},{"cell_type":"markdown","metadata":{"id":"cuV6KlvrmWvF"},"source":["> Testando modelo treinado de modo a obter as posições das bounding boxes e o grau de confiança de cada uma."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z-70hsfmmYk7"},"outputs":[],"source":["dir = '/content/imagens/'\n","filename = '[CAMINHO]/filename_detecPlaca.txt' # ARQUIVO CONTENDO NOMES DAS IMAGENS DE TESTES\n","temp = open(filename, 'r').read().splitlines()\n","\n","im = [dir + x for x in temp]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ifp8mjeF71DT"},"outputs":[],"source":["# TESTES\n","\n","model = torch.hub.load('ultralytics/yolov5', 'custom', '[MODELO TREINADO]')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p3j_PIVAU3GA"},"outputs":[],"source":["!cd images_inference"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nX02tlx8cxLB"},"outputs":[],"source":["import cv2\n","from google.colab.patches import cv2_imshow\n","print('Resultados da Inferência no Conjunto de Testes:\\n')\n","\n","for i in range(0, len(im)):\n"," results = model(im[i])\n"," print(im[i][17:37])\n"," if results.xyxy[0].numel() == 0:\n","   continue\n"," tensor = results.xyxy[0][0]\n"," \n"," xi = tensor[0]\n"," xf = tensor[2]\n"," yi = tensor[1]\n"," yf = tensor[3]\n"," cf = tensor[4]\n"," xi = int(round(xi.item(), 0))\n"," xf = int(round(xf.item(), 0))\n"," yi = int(round(yi.item(), 0))\n"," yf = int(round(yf.item(), 0))\n"," bboxes = [i+1, yi, yf, xi, xf, cf.item()]\n"," print(bboxes)\n","\n"," img = cv2.imread(im[i])\n"," img_crop = img[yi:yf, xi:xf]\n"," cv2_imshow(img_crop)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HbciFu0L8BJq"},"outputs":[],"source":["import cv2\n","\n","for i in range(0, len(im)):\n"," results = model(im[i])\n"," \n"," if results.xyxy[0].numel() == 0:\n","   continue\n"," tensor = results.xyxy[0][0]\n"," xi = tensor[0]\n"," xf = tensor[2]\n"," yi = tensor[1]\n"," yf = tensor[3]\n"," cf = tensor[4]\n"," cf = cf.item()\n"," cf = str(cf)\n"," cf = cf[0:5]\n"," cf = float(cf)\n"," #print(cf)\n"," xi = int(round(xi.item(), 0))\n"," xf = int(round(xf.item(), 0))\n"," yi = int(round(yi.item(), 0))\n"," yf = int(round(yf.item(), 0))\n"," bboxes = [i+1, yi, yf, xi, xf, cf]\n","\n"," #print(im[i])\n"," img = cv2.imread(im[i])\n"," img_crop = img[yi:yf, xi:xf]\n"," #cv2.imwrite('/content/yolov5/images_inference/'+str(i+1)+'.png', img_crop)\n"," cv2.imwrite('/content/yolov5/images_inference/'+im[i][24:37]+'.png', img_crop)\n"," #cv2_imshow(img_crop)\n"," with open('bboxes.txt', 'a') as f:\n","    f.write('\\n')\n","    f.writelines(str(bboxes))\n"," f.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XTZVixDsWIV3"},"outputs":[],"source":["!cp -r /content/yolov5/images_inference2/ -d [CAMINHO PARA SALVAR RESULTADOS]"]},{"cell_type":"markdown","metadata":{"id":"7Gh9vZNL5iG2"},"source":["# Convertendo do formato pytorch para o formato TFLITE para poder utilizar em smartphones"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gWaH_y2d5iG3"},"outputs":[],"source":["# Converte para formato fp16 TFlite\n","\n","!python export.py --weights [MODELO TREINADO] --include tflite --data dataset.yaml --img 1056"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ahVJOc1r5iG3"},"outputs":[],"source":["# Testando Modelo FP16\n","\n","!python detect.py --weights /content/yolov5/runs/train/exp/weights/best-int8.tflite --img 1056 --conf 0.25 --data dataset.yaml --source [IMAGENS DE TESTE]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xPg8mb2N8J8G"},"outputs":[],"source":["!cp -r /content/yolov5/runs/detect/exp2/ -d /content/drive/MyDrive/ # COPIA ARQUIVOS DO MODELO CONVERTIDO"]},{"cell_type":"markdown","metadata":{"id":"AeAx3JOm5iG4"},"source":["# Converte para formato int8"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YX21Sd_y5iG4"},"outputs":[],"source":["!python export.py --weights [MODELO TREINADO] --include tflite --int8 --img 1056 --data  dataset.yaml"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":0}
