{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"LteZiT4P5iGW"},"outputs":[],"source":["import torch # Importa biblioteca do pytorch\n","from IPython.display import Image # Importa biblioteca para printar imagens"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5exHMQuYCKy-"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive') # importa arquivos do google drive para o disco da máquina virtual"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sSgR_5PUCl3U"},"outputs":[],"source":["!mkdir imagens\n","!unzip [CAMINHO_IMAGENS_ZIPADAS] -d /content/imagens/ # descompacta imagens a serem utilizadas no treinamento/teste/validação\n","!git clone https://github.com/ultralytics/yolov5 # importa yolov5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1-K6HoWl5iGg"},"outputs":[],"source":["%cd yolov5\n","!pip install -r requirements.txt # instala bibliotecas necessárias para utilizar o yolov5\n","!pip install IProgress"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IapksgnC5iGl"},"outputs":[],"source":["from tqdm import tqdm\n","from ipywidgets import IntProgress"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4CdruxcN5iGm"},"outputs":[],"source":["torch.cuda.get_arch_list()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XM3ZwIhK5iGo"},"outputs":[],"source":["print('Versão Pytorch: %s com %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"]},{"cell_type":"markdown","metadata":{"id":"72WTm2Cr5iGp"},"source":["# Treinamento do Modelo YoloV5\n"]},{"cell_type":"markdown","metadata":{"id":"aNSlUEGz5iGt"},"source":[" > Copiar arquivos para treinamento.\n"," \n"," > Copiar arquivo dataset.yaml para o Diretório: yolov5/data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5wJHN0yd5iGv"},"outputs":[],"source":["!python train.py --img 256 --rect --batch 64 --epochs 50 --data [CAMINHO]/dataset.yaml --weights yolov5m.pt --cache\n","!cp -r /content/yolov5/runs/train/exp/ -d [CAMINHO]\n","from google.colab import runtime\n","runtime.unassign()"]},{"cell_type":"markdown","metadata":{"id":"4JKFe7zKLmVu"},"source":["> Copia resultados do treinamento para pasta no google drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GQJ6ujBv0y3S"},"outputs":[],"source":["!cp -r /content/yolov5/runs/train/exp/ -d [CAMINHO]"]},{"cell_type":"markdown","metadata":{"id":"ZSXjKv-75iGz"},"source":["# Testando o Modelo Treinado:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u9jUKWW05iG0"},"outputs":[],"source":["Image(filename='runs/train/exp/val_batch0_labels.jpg', width=256)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rZrtGIlG5iG2"},"outputs":[],"source":["!python detect.py --weights [CAMINHO]/best_yolov5m_seg.pt --img 256 --conf 0.25 --source /content/imagens/testing/images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FXHBpWJ-2kzK"},"outputs":[],"source":["!cp -r /content/yolov5/runs/detect/exp/ -d [CAMINHO]"]},{"cell_type":"markdown","metadata":{"id":"eLOHMLTSL-Bg"},"source":["> Testando modelo treinado de modo a obter as posições das bounding boxes e o grau de confiança de cada uma."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BypNpRpNuLqD"},"outputs":[],"source":["dir = '/content/imagens/'\n","filename = '[CAMINHO]/filename_plates_infer.txt'\n","temp = open(filename, 'r').read().splitlines()\n","\n","im = [dir + x for x in temp]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y2oh_ecaHY0o"},"outputs":[],"source":["# inferência para obter coordenadas\n","\n","# ANOTA PREDIÇÕES\n","%cd /content/\n","with open('resultados.txt', 'w') as f:\n","    f.write('Resultados')\n","f.close()\n","\n","model = torch.hub.load('ultralytics/yolov5', 'custom', '[CAMINHO]/best.pt')  # custom trained model\n","\n","for i in range(0, len(im)):\n"," results = model(im[i], size = 256)\n","\n"," with open('resultados.txt', 'a') as f:\n","  f.write('\\n')\n","  f.writelines('Imagem ')\n","  f.writelines(str(i+1))\n"," f.close()\n","\n"," stringcat = ''\n"," for j in range(0, len(results.xyxy[0])):\n","  stringcat = ''\n","  for k in range(0, 4):\n","   stringcat = stringcat + ' ' + str(round(float(results.xyxy[0][j][k])))\n","  stringcat = stringcat + ' ' +  str(float(results.xyxy[0][j][4]))\n","  with open('resultados.txt', 'a') as f:\n","     f.write('\\n')\n","     f.writelines(stringcat)\n","  f.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B0nDrme_Uih_"},"outputs":[],"source":["print(results.xyxy[0][0][0])\n","x = results.xyxy[0][0][0]\n","print(int(x))"]},{"cell_type":"markdown","metadata":{"id":"7Gh9vZNL5iG2"},"source":["# Convertendo do formato pytorch para o formato TFLITE para poder utilizar em smartphones"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gWaH_y2d5iG3"},"outputs":[],"source":["# Converte para formato fp16 TFlite\n","\n","!python export.py --weights [CAMINHO]/best.pt --include tflite --data dataset.yaml --img 256"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ahVJOc1r5iG3"},"outputs":[],"source":["# Testando Modelo FP16\n","\n","!python detect.py --weights [CAMINHO]best-fp16.tflite --img 256 --conf 0.25 --data dataset.yaml --source /content/imagens/testing/images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xPg8mb2N8J8G"},"outputs":[],"source":["!cp -r /content/yolov5/runs/detect/exp2/ -d /content/drive/MyDrive/Dados/testes/"]},{"cell_type":"markdown","metadata":{"id":"AeAx3JOm5iG4"},"source":["# Converte para formato int8"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YX21Sd_y5iG4"},"outputs":[],"source":["!python export.py --weights [CAMINHO]/best_yolov5m_seg.pt --include tflite --int8 --img 256 --data dataset.yaml"]},{"cell_type":"markdown","metadata":{"id":"R2g68lScQI8k"},"source":["# AVALIANDO PERFORMANCE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NK5Zmr2kQM9M"},"outputs":[],"source":["# INICIALIZA RECURSOS NECESSÁRIOS PARA TESTAR O MODELO\n","\n","import torch # Importa biblioteca do pytorch\n","from google.colab import drive\n","drive.mount('/content/drive') # importa arquivos do google drive para o disco da máquina virtual\n","!mkdir imagens\n","!unzip [CAMINHO ARQUIVO ZIP] -d /content/imagens/ # descompacta imagens a serem utilizadas no treinamento/teste/validação\n","!git clone https://github.com/ultralytics/yolov5 # importa yolov5\n","%cd yolov5\n","!pip install -r requirements.txt # instala bibliotecas necessárias para utilizar o yolov5\n","!pip install IProgress\n","from tqdm import tqdm\n","import IProgress\n","from ipywidgets import IntProgress"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0XTb92gyQW2c"},"outputs":[],"source":["!python val.py --weights [CAMINHO]/best_yolov5m_seg.pt --data segmentation.yaml --img 256 --task test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jHC_z_zBQc4E"},"outputs":[],"source":["model = torch.hub.load('ultralytics/yolov5', 'custom', '[CAMINHO]/best_yolov5m_seg.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XBViKbxAQeeP"},"outputs":[],"source":["dir = '[CAMINHO IMAGENS TESTE]'\n","filename = '[CAMINHO ARQUIVO COM O NOME DAS IMAGENS]/FilenamePlacaAvalGeral.txt'\n","temp = open(filename, 'r').read().splitlines()\n","\n","im = [dir + x for x in temp]\n","\n","for i in range(0, len(im)):\n","\n"," results = model(im[i], size = 256)\n"," a=1\n"," if results.xyxy[0].numel() == 0:\n","  bboxes = [i+1, a, im[i][32:45]+'.png', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A']\n","  with open('deteccoes_model_aval_geral.txt', 'a') as f:\n","    f.write('\\n')\n","    f.writelines(str(bboxes))\n","  f.close()\n","  continue\n"," for j in range(0, len(results.xyxy[0])):\n","    tensor = results.xyxy[0][j]\n","    xi = tensor[0]\n","    xf = tensor[2]\n","    yi = tensor[1]\n","    yf = tensor[3]\n","    cf = tensor[4]\n","    cf = cf.item()\n","    cf = str(cf)\n","    cf = cf[0:5]\n","    cf = float(cf)\n","    xi = int(round(xi.item(), 0))\n","    xf = int(round(xf.item(), 0))\n","    yi = int(round(yi.item(), 0))\n","    yf = int(round(yf.item(), 0))\n","    bboxes = [i+1, a, im[i][64:81], yi, yf, xi, xf, cf]\n","    print(bboxes)\n","    a = a + 1\n","\n","    with open('deteccoes_model_aval_geral.txt', 'a') as f:\n","        f.write('\\n')\n","        f.writelines(str(bboxes))\n","    f.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TWSiq9y8XxrN"},"outputs":[],"source":["print(im[1][64:81])"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":0}
