{"cells":[{"cell_type":"markdown","metadata":{"id":"ndJ6sHyprwut"},"source":["# RECONHECIMENTO COM CNN"]},{"cell_type":"markdown","metadata":{"id":"4AcB5Prgk3KT"},"source":["# IMPORTANDO O DATASET"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NheajyGir9sp"},"outputs":[],"source":["import tensorflow as tf\n","from keras import layers\n","from keras import models\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from google.colab.patches import cv2_imshow\n","import cv2\n","from tensorflow import keras"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lq4SD2pZknNk"},"outputs":[],"source":["# IMPORTANDO DATASET\n","from google.colab import drive\n","drive.mount('/content/drive') # importa arquivos do google drive para o disco da máquina virtual"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PRrLr4sclyP_"},"outputs":[],"source":["!mkdir dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e4eTPHIFluMz"},"outputs":[],"source":["%cd dataset\n","!mkdir chars\n","#!mkdir nums"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SeNcmd_il3Wo"},"outputs":[],"source":["!unzip [CAMINHO IMAGENS ZIPADAS]/.zip -d /content/dataset/chars/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v3zqad3vWQ76"},"outputs":[],"source":["# DEFINE TAMANHO DA IMAGENS APÓS RESIZE\n","r = 30\n","c = 20\n","color = (0,0,0)\n","\n","# DEFINE CAMINHOS PARA ARQUIVOS DE TREINAMENTO/TESTE E INFERÊNCIA\n","\n","dir_chars_train = '[CAMINHO]' # DIRETÓRIO COM AS IMAGENS DE TREINAMENTO\n","dir_chars_train_lbl = '[CAMINHO]' # DIRETÓRIO COM OS LABELS DAS IMAGENS DE TREINAMENTO\n","filename_chars_train = '[CAMINHO].txt' # ARQUIVO COM O NOME DO ARQUIVO DE CADA IMAGEM\n","\n","dir_chars_valid = '[CAMINHO]' # DIRETÓRIO COM AS IMAGENS DE VALIDAÇÃO\n","dir_chars_valid_lbl = '[CAMINHO]' # DIRETÓRIO COM OS LABELS DAS IMAGENS DE VALIDAÇÃO\n","filename_chars_valid = '[CAMINHO]/.txt' # ARQUIVO COM O NOME DO ARQUIVO DE CADA IMAGEM\n","\n","dir_chars_test = '[CAMINHO]' # DIRETÓRIO COM AS IMAGENS DE TESTES\n","dir_chars_test_lbl = '[CAMINHO]' # DIRETÓRIO COM OS LABELS DAS IMAGENS DE TESTES\n","filename_chars_test = '[CAMINHO]/.txt'# ARQUIVO COM O NOME DO ARQUIVO DE CADA IMAGEM\n","\n","num_classes = 26"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9rLvYFk8b1wr"},"outputs":[],"source":["# FUNÇÃO QUE REDIMENSIONA IMAGENS DOS CARACTERES E ADICIONA UM PADDING\n","def redimensiona_img(img, r, c, color):\n","  old_image_height, old_image_width, channels = img.shape\n","\n","  if old_image_height > old_image_width:\n","    new_image_width = old_image_height\n","    new_image_height = old_image_height\n","  else:\n","    new_image_width = old_image_width\n","    new_image_height = old_image_width\n","\n","  result = np.full((new_image_height,new_image_width, channels), color, dtype=np.uint8)\n","  x_center = (new_image_width - old_image_width) // 2\n","  y_center = (new_image_height - old_image_height) // 2\n","\n","  #print(x_center)\n","  #print(y_center)\n","  #print(img.shape)\n","\n","  result[y_center:y_center+old_image_height,\n","       x_center:x_center+old_image_width] = img\n","\n","  img = cv2.resize(result, ( c, r ))\n","\n","  return img"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1zcWq0acAFOH"},"outputs":[],"source":["# FUNÇÃO QUE REDIMENSIONA IMAGENS DOS CARACTERES\n","def redimensiona_img_nopad(img, r, c):\n","\n","  img = cv2.resize(img, ( c, r ))\n","\n","  return img"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_I0RCdKQol17"},"outputs":[],"source":["# FUNÇÃO DE LEITURA DAS IMAGENS E LABELS DOS CARACTERES\n","\n","def read_imgs_n_lbls(dir_imgs, dir_lbl, filenames_txt):\n","  temp = open(filenames_txt, 'r').read().splitlines()\n","  im = [dir_imgs + x for x in temp]\n","\n","  imgs = []\n","  lbls = []\n","\n","  for i in range(0, len(im)):\n","    img = cv2.imread(im[i])\n","\n","    img = redimensiona_img(img, r, c, color)\n","    imgs.append(img)\n","    \n","    if(dir_lbl != 'N/A'):\n","      lbl_name = im[i][:-3] + 'txt'\n","      lbl_name = lbl_name[-20:]\n","      f_lbl = open(dir_lbl + lbl_name, 'r')\n","      lbl = f_lbl.readline()\n","      f_lbl.close()\n","\n","      lbl = lbl.split()\n","      lbl = lbl[0]\n","\n","      lbls.append(lbl)\n","\n","  return imgs, lbls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A9W3yqlFeWkS"},"outputs":[],"source":["# LENDO IMAGENS DE TREINAMENTO (LETRAS)\n","[imgs_train, lbls_train] = read_imgs_n_lbls( dir_chars_train, dir_chars_train_lbl, filename_chars_train )\n","print(\"fim imagens treinamento\")\n","[imgs_valid, lbls_valid] = read_imgs_n_lbls( dir_chars_valid, dir_chars_valid_lbl, filename_chars_valid )\n","print(\"fim imagens validação\")\n","[imgs_test, lbls_test] = read_imgs_n_lbls( dir_chars_test, dir_chars_test_lbl, filename_chars_test )\n","print(\"fim imagens testing\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YOQh0k5M78Dw"},"outputs":[],"source":["# PLOTA TAMANHOS DOS SETS DE IMAGENS\n","print(len(imgs_train))\n","print(len(imgs_valid))\n","print(len(imgs_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UstUJ_d11tpa"},"outputs":[],"source":["# concatena conjunto de treino e validação\n","for i in range( 0, len(imgs_valid) ):\n","  imagem = imgs_valid[i]\n","  imgs_train.append(imagem)\n","\n","print('Tamanho do dataset train+valid = ' + str(len(imgs_train)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XPeXxpAZINNt"},"outputs":[],"source":["# concatena conjunto de treino e validação\n","for i in range( 0, len(lbls_valid) ):\n","  label = lbls_valid[i]\n","  lbls_train.append(label)\n","\n","print('Tamanho dos labels do dataset train+valid = ' + str(len(lbls_train)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UO_Vm69mCGN7"},"outputs":[],"source":["# REDIMENSIONAR IMAGENS PARA O INTERVALO [0, 1]\n","imgs_train = tf.keras.utils.normalize(imgs_train, axis=1)\n","#imgs_valid = tf.keras.utils.normalize(imgs_valid, axis=1)\n","imgs_test = tf.keras.utils.normalize(imgs_test, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kncwron62I0X"},"outputs":[],"source":["# CONVERTE VETORES DE CLASS EM MATRIZES DE CLASSES BINÁRIAS\n","lbls_train = keras.utils.to_categorical(lbls_train, num_classes)\n","lbls_test = keras.utils.to_categorical(lbls_test, num_classes)"]},{"cell_type":"markdown","metadata":{"id":"DKn4Zxpzk61x"},"source":["# MONTANDO E TREINANDO A CNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ZGz-s2esYEZ"},"outputs":[],"source":["model = models.Sequential()\n","model.add(layers.Conv2D(32, (3, 3), padding=\"same\", activation='relu', input_shape=(r, c, 3)))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(128, (3, 3), padding=\"same\", activation='relu'))\n","model.add(layers.Conv2D(64, (1, 1), padding=\"same\", activation='relu'))\n","model.add(layers.Conv2D(128, (3, 3), padding=\"same\", activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(256, (3, 3), padding=\"same\", activation='relu'))\n","model.add(layers.Conv2D(128, (1, 1), padding=\"same\", activation='relu'))\n","model.add(layers.Conv2D(256, (3, 3), padding=\"same\", activation='relu'))\n","model.add(layers.Conv2D(512, (3, 3), padding=\"same\", activation='relu'))\n","model.add(layers.Conv2D(256, (1, 1), padding=\"same\", activation='relu'))\n","model.add(layers.Conv2D(512, (3, 3), padding=\"same\", activation='relu'))\n","model.add(layers.Conv2D(155, (1, 1), padding=\"same\", activation='relu'))\n","model.add(layers.Dropout(0.25))\n","model.add(layers.Flatten())\n","model.add(layers.Dense(26,activation=\"softmax\"))\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OBkZuZ_oatUI"},"outputs":[],"source":["model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6GcW0TDRxV0_"},"outputs":[],"source":["batch_size = 128\n","epochs = 15"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PWHunZhnbsmU"},"outputs":[],"source":["# REALIZA O TREINO, SALVA E ENCERRA EXECUÇÃO\n","model.fit(imgs_train,  lbls_train, batch_size=batch_size, epochs=epochs, validation_split=0.33)\n","\n","%cd /content/\n","model_name = 'NOMEMODELOTREINADO.model'\n","model.save(model_name)\n","!cp -r /content/num_rec_v01.model -d /content/drive/MyDrive/Experimentos_CNN/\n","from google.colab import runtime\n","runtime.unassign()"]},{"cell_type":"markdown","metadata":{"id":"9F1AxAmYYH-v"},"source":["# AVALIANDO A CNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H9aeKAZSVm0S"},"outputs":[],"source":["# AVALIA MODELO NO CONJ DE TESTES\n","score = model.evaluate(imgs_test, lbls_test, verbose=0)\n","print(\"Test loss:\", score[0])\n","print(\"Test accuracy:\", score[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sdQwmN7TLBrq"},"outputs":[],"source":["# CARREGA MODELO SALVO\n","\n","dir_models = 'CAMINHO'\n","model_name = 'MODELO.model'\n","model = tf.keras.models.load_model(dir_models + model_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"40EdM4TMa_vU"},"outputs":[],"source":["converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_model = converter.convert()\n","\n","with open(\"model.tflite\", 'wb') as f:\n","  f.write(tflite_model)"]},{"cell_type":"markdown","metadata":{"id":"N4HJyuKhRYvJ"},"source":["## AVALIANDO MODELO"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kg80hPwKRaMo"},"outputs":[],"source":["# Avaliando Modelos\n","\n","import tensorflow as tf\n","import numpy as np\n","import cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HfcI4ym7-X_s"},"outputs":[],"source":["# IMPORTANDO DATASET\n","from google.colab import drive\n","drive.mount('/content/drive') # importa arquivos do google drive para o disco da máquina virtual\n","print(\"conexão com o google drive estabelecida\")\n","!mkdir dataset\n","%cd dataset\n","\n","!unzip [CAMINHO IMAGENS ZIPADAS].zip -d /content/dataset/\n","print(\"imagens e labels descarregados\")\n","\n","# DEFINE TAMANHO DA IMAGENS APÓS RESIZE\n","r = 30\n","c = 20\n","color = (0,0,0)\n","\n","# DEFINE CAMINHOS PARA ARQUIVOS DE TREINAMENTO/TESTE E INFERÊNCIA ------- CHARS ORIGINAIS RECORTADOS\n","\n","dir_chars_test = '/content/dataset/'\n","dir_chars_test_lbl = '/content/dataset/'\n","filename_chars_test = '[CAMINHO PARA ARQUIVO COM NOMES DAS IMAGENS]filename_numbers_avageral.txt'\n","\n","num_classes = 10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CAXh5uWFBzOD"},"outputs":[],"source":["# FUNÇÃO DE LEITURA DAS IMAGENS E LABELS DOS CARACTERES\n","\n","def read_imgs_n_lbls(dir_imgs, dir_lbl, filenames_txt):\n","  temp = open(filenames_txt, 'r').read().splitlines()\n","  im = [dir_imgs + x for x in temp]\n","\n","  imgs = []\n","  lbls = []\n","\n","  for i in range(0, len(im)):\n","    img = cv2.imread(im[i])\n","\n","    img = redimensiona_img(img, r, c, color)\n","    imgs.append(img)\n","\n","    if(dir_lbl != 'N/A'):\n","      lbl_name = im[i][:-3] + 'txt'\n","      lbl_name = lbl_name[-20:]\n","      f_lbl = open(dir_lbl + lbl_name, 'r')\n","      lbl = f_lbl.readline()\n","      f_lbl.close()\n","\n","      lbl = lbl.split()\n","      lbl = lbl[0]\n","\n","      lbls.append(lbl)\n","\n","  print(\"leitura de imagens e rótulos após reajustes finalizada\")\n","  return imgs, lbls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7iD6O98SB4J5"},"outputs":[],"source":["# RODA O TESTE\n","\n","# LENDO IMAGENS DE TESTES\n","[imgs_test, lbls_test] = read_imgs_n_lbls( dir_chars_test, 'N/A', filename_chars_test )\n","print(\"fim imagens teste\")\n","\n","# PLOTA TAMANHO DO SET DE IMAGENS\n","print(\"Número de imagens do conjunto de testes: \" + str( len(imgs_test) ) )\n","print(\"Número de labels do conjunto de testes: \" + str( len(lbls_test) ) )\n","\n","# REDIMENSIONAR IMAGENS PARA O INTERVALO [0, 1]\n","imgs_test = tf.keras.utils.normalize(imgs_test, axis=1)\n","\n","# CONVERTE VETORES DE CLASS EM MATRIZES DE CLASSES BINÁRIAS\n","#lbls_test = keras.utils.to_categorical(lbls_test, num_classes)\n","\n","# CARREGA MODELO SALVO\n","dir_models = '[CAMINHO DIRETÓRIO COM MODELOS SALVOS]'\n","model_name = 'MODEL.model'\n","model = tf.keras.models.load_model(dir_models + model_name)\n","\n","# AVALIA MODELO NO CONJ DE TESTES\n","score = model.evaluate(imgs_test, lbls_test, verbose=0)\n","print(\"Test loss:\", score[0])\n","print(\"Test accuracy:\", score[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-1gf91LaGKme"},"outputs":[],"source":["# ANOTA PREDIÇÕES\n","%cd /content/\n","with open('RESULTADOS.txt', 'w') as f:\n","    f.write('Resultados')\n","f.close()\n","\n","for i in range( 0, len(imgs_test) ):\n","  img = imgs_test[i]\n","  preds = model.predict(np.array([img]))\n","  classes = np.argmax(preds, axis = 1)\n","  with open('RESULTADOS.txt', 'a') as f:\n","    f.write('\\n')\n","    f.writelines(str(classes))\n","  f.close()\n","\n","!cp -r /content/RESULTADOS.txt -d /content/drive/MyDrive/"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMdX/MRVkYoKxa0q2Ozxcff","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
